{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15bf55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca041cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "with open('sales_data2.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    detected_encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {detected_encoding}\")\n",
    "\n",
    "df = pd.read_csv('sales_data2.csv', encoding=detected_encoding)\n",
    "df.to_csv('sales_data2.csv', encoding='utf-8', index=False)\n",
    "\n",
    "df = pd.read_csv('sales_data2.csv', encoding='utf-8')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e21d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['MONTH'] = df['Order Date'].dt.month\n",
    "df['DAY'] = df['Order Date'].dt.day\n",
    "df['YEAR'] = df['Order Date'].dt.year\n",
    "df['TIME'] = df['Order Date'].dt.time\n",
    "\n",
    "# Create automated index for categories\n",
    "df['CATEGORY_ID'] = pd.factorize(df['catégorie'])[0] + 1\n",
    "\n",
    "# Create automated index for products\n",
    "df['PRODUCT_ID'] = pd.factorize(df['Product'])[0] + 1\n",
    "\n",
    "# Drop the Product_ean column if it exists\n",
    "if 'Product_ean' in df.columns:\n",
    "    df = df.drop('Product_ean', axis=1)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59298387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xarxa Neuronal amb TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preparar les dades\n",
    "df_nn = df.copy()\n",
    "\n",
    "# Drop les columnes categòriques originals ja que tenim IDs\n",
    "df_nn = df_nn.drop(['catégorie', 'Product'], axis=1)\n",
    "\n",
    "# Encode columnes categòriques restants\n",
    "categorical_cols_nn = df_nn.select_dtypes(include=['object']).columns\n",
    "label_encoders_nn = {}\n",
    "for col in categorical_cols_nn:\n",
    "    le = LabelEncoder()\n",
    "    df_nn[col] = le.fit_transform(df_nn[col].astype(str))\n",
    "    label_encoders_nn[col] = le\n",
    "\n",
    "# Separar features i target\n",
    "X_nn = df_nn.drop(['turnover', 'margin', 'Order Date'], axis=1)\n",
    "y_nn = df_nn['turnover']\n",
    "\n",
    "# Split train/test\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_nn, y_nn, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalitzar les dades (important per xarxes neuronals!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_nn)\n",
    "X_test_scaled = scaler.transform(X_test_nn)\n",
    "\n",
    "print(f\"Nombre de features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"Train samples: {X_train_scaled.shape[0]}\")\n",
    "print(f\"Test samples: {X_test_scaled.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el model de Xarxa Neuronal\n",
    "model_nn = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)  # Output layer per regressió\n",
    "])\n",
    "\n",
    "# Compilar el model\n",
    "model_nn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Veure l'arquitectura del model\n",
    "model_nn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d02587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el model\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=50,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "history = model_nn.fit(\n",
    "    X_train_scaled, y_train_nn,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c49a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzar el procés d'entrenament\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Model MAE During Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluar el model\n",
    "y_pred_nn = model_nn.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Calcular mètriques\n",
    "mse_nn = mean_squared_error(y_test_nn, y_pred_nn)\n",
    "rmse_nn = np.sqrt(mse_nn)\n",
    "r2_nn = 1 - (np.sum((y_test_nn - y_pred_nn)**2) / np.sum((y_test_nn - y_test_nn.mean())**2))\n",
    "mae_nn = np.mean(np.abs(y_test_nn - y_pred_nn))\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"XARXA NEURONAL - Resultats\")\n",
    "print(\"=\" * 50)\n",
    "print(f'MSE:  {mse_nn:.2f}')\n",
    "print(f'RMSE: {rmse_nn:.2f}')\n",
    "print(f'MAE:  {mae_nn:.2f}')\n",
    "print(f'R² Score: {r2_nn:.4f}')\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Comparar amb RandomForest\n",
    "print(\"\\nCOMPARACIÓ AMB RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "print(f'Random Forest MSE:  {mse:.2f}')\n",
    "print(f'Random Forest RMSE: {rmse:.2f}')\n",
    "print(f'Random Forest R²:   {r2_score:.4f}')\n",
    "print(\"=\" * 50)\n",
    "print(f'\\nMillora en RMSE: {((rmse - rmse_nn) / rmse * 100):.2f}%')\n",
    "print(f'Millora en R²: {((r2_nn - r2_score) / r2_score * 100):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a027038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzar resultats de la Xarxa Neuronal\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Predicted vs Actual\n",
    "axes[0].scatter(y_test_nn, y_pred_nn, alpha=0.5, color='blue')\n",
    "axes[0].plot([y_test_nn.min(), y_test_nn.max()], [y_test_nn.min(), y_test_nn.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Turnover')\n",
    "axes[0].set_ylabel('Predicted Turnover')\n",
    "axes[0].set_title(f'Neural Network: Predicted vs Actual\\nR² = {r2_nn:.4f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals_nn = y_test_nn - y_pred_nn\n",
    "axes[1].scatter(y_pred_nn, residuals_nn, alpha=0.5, color='green')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Turnover')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title(f'Residual Plot\\nRMSE = {rmse_nn:.2f}')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Distribution of Errors\n",
    "axes[2].hist(residuals_nn, bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[2].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[2].set_xlabel('Residuals')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title(f'Distribution of Prediction Errors\\nMAE = {mae_nn:.2f}')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
